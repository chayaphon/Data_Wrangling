{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : Index\n",
      "1 : Vol. of Txn by Payment System\n",
      "2 : Value of Txn by Payment System\n",
      "3 : Vol. of Plastic card usage\n",
      "4 : Value. of Plastic card usage\n",
      "5 : number of cards\n",
      "6 : No of EFTPOS Terminals <2018\n",
      "7 : No of EFTPOS Terminals 2018+\n",
      "8 : Payment Cards on ATM & POS \n",
      "9 : Mobile,internet banking\n",
      "10 : Mobile,internet banking add\n",
      "11 : Bill Payment\n",
      "12 : Vol. of e-payment\n",
      "13 : Value. of e-payment\n",
      "14 : e-Money\n",
      "15 : Foreign cards & emoney\n",
      "16 : Thai cards spent abroad\n",
      "17 : promptpay\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Define sheet name\n",
    "FILE_NAME = '../Sources/Data.xlsx'\n",
    "\n",
    "# Get all sheet name in Excel file\n",
    "sheet_name_list = pd.ExcelFile(FILE_NAME).sheet_names\n",
    "\n",
    "# Show all sheet name and index number\n",
    "for index, sheet_name in enumerate(sheet_name_list):\n",
    "    print(f\"{index} : {sheet_name}\")\n",
    "\n",
    "# Read data base on selected SELECT_SHEET_NAME\n",
    "SELECT_SHEET_NAME_1 = sheet_name_list[1]\n",
    "SELECT_SHEET_NAME_2 = sheet_name_list[2]\n",
    "\n",
    "# add dataframe for Volume and Value sheet\n",
    "df_volume = pd.read_excel(FILE_NAME, sheet_name= SELECT_SHEET_NAME_1, skiprows = 5)\n",
    "df_value = pd.read_excel(FILE_NAME, sheet_name= SELECT_SHEET_NAME_2, skiprows = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Data Cleansing ###\n",
    "\n",
    "# ---Payment Volume ---#\n",
    "# Change column name and drop un-related column\n",
    "df_volume.rename(columns = {\"Unnamed: 1\" : \"Attribute\"}, inplace = True)\n",
    "df_volume.dropna(subset = [\"Attribute\"], inplace = True)\n",
    "df_volume.drop(columns = [\"Unnamed: 0\"], inplace = True)\n",
    "df_volume.replace(\"n.a.\", np.nan, inplace = True)\n",
    "\n",
    "# Filter out last row of column 'Attribute'\n",
    "df_volume = df_volume[df_volume['Attribute'] != \"Total\"]\n",
    "\n",
    "# Cleansing Column name (trim and remove leeter after year)\n",
    "col_list_clean_volume = []\n",
    "col_list_trim_volume = [col_name.strip() for col_name in df_volume.columns]\n",
    "for col_name in col_list_trim_volume:\n",
    "    if len(col_name.split(\" \")) <= 2:\n",
    "        col_list_clean_volume.append(col_name)\n",
    "    else:\n",
    "        cleaned_col_name =  \" \".join(col_name.split(\" \")[:-1])\n",
    "        col_list_clean_volume.append(cleaned_col_name)\n",
    "        \n",
    "# Overwrite existing column with new columns clean column    \n",
    "df_volume.columns = col_list_clean_volume\n",
    "\n",
    "\n",
    "# ---Payment Value ---#\n",
    "# Change column name and drop un-related column\n",
    "df_value.rename(columns = {\"Unnamed: 1\" : \"Attribute\"}, inplace = True)\n",
    "df_value.dropna(subset = [\"Attribute\"], inplace = True)\n",
    "df_value.drop(columns = [\"Unnamed: 0\"], inplace = True)\n",
    "df_value.replace(\"n.a.\", np.nan, inplace = True)\n",
    "\n",
    "# Filter out last row of column 'Attribute'\n",
    "df_value = df_value[df_value['Attribute'] != \"Total\"]\n",
    "\n",
    "# Cleansing Column name (trim and remove leeter after year)\n",
    "col_list_clean_volume = []\n",
    "col_list_trim_volume = [col_name.strip() for col_name in df_volume.columns]\n",
    "for col_name in col_list_trim_volume:\n",
    "    if len(col_name.split(\" \")) <= 2:\n",
    "        col_list_clean_volume.append(col_name)\n",
    "    else:\n",
    "        cleaned_col_name =  \" \".join(col_name.split(\" \")[:-1])\n",
    "        col_list_clean_volume.append(cleaned_col_name)\n",
    "        \n",
    "# Overwrite existing column with new columns clean column    \n",
    "df_value.columns = col_list_clean_volume\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Data Cleansing 2 ###\n",
    "# Remove /Number from 'Attribute' columns\n",
    "text_clean_list = []\n",
    "for text in list(df_volume['Attribute']):\n",
    "    if text.split(\" \")[-1].endswith(\"/\"):\n",
    "        text_clean_list.append(\" \".join(text.split(\" \")[:-1]))\n",
    "    else:\n",
    "        text_clean_list.append(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Data Shaping1 ###\n",
    "\n",
    "# Seperate each attribute as parent and sub-topic\n",
    "result_text_list = []\n",
    "Parent = []\n",
    "\n",
    "for index in range(len(text_clean_list)):\n",
    "    list_text = text_clean_list[index].split(\"   \")\n",
    "    \n",
    "    if len(list_text[0]) > 2 :\n",
    "        if not list_text[0][2].isdigit():\n",
    "            Parent = [list_text[0].strip()]\n",
    "            result_text_list.append(Parent[0])\n",
    "        else:\n",
    "            Parent = Parent[:1]\n",
    "            Parent.append(list_text[0].strip())\n",
    "            result_text_list.append(\" ::: \".join(Parent))\n",
    "    elif list_text[1][0].isdigit():\n",
    "        Parent = Parent[:1]\n",
    "        Parent.append(list_text[1].strip())\n",
    "        result_text_list.append(\" ::: \".join(Parent))\n",
    "    else:\n",
    "        Parent = Parent[:2]\n",
    "        Parent.append(list_text[1].strip())\n",
    "        result_text_list.append(\" ::: \".join(Parent))\n",
    "        \n",
    "# Remove Number from 'Attribute' columns (both Volume/Value share the same Attribute)\n",
    "result_text_list_2 = []\n",
    "for text in result_text_list:\n",
    "    list_text = text.split(\" ::: \")\n",
    "    for text2 in list_text:\n",
    "        if text2[:1].isdigit():\n",
    "            index = list_text.index(text2)\n",
    "            list_text[index] = \" \".join(text2.split(\" \")[1:])\n",
    "    result_text_list_2.append(\" ::: \".join(list_text))        \n",
    "       \n",
    "        \n",
    "# Assign new value to 'Attribute' column \n",
    "df_volume['Attribute'] = result_text_list_2\n",
    "df_value['Attribute'] = result_text_list_2\n",
    "\n",
    "# Expland Attribute into multiple columns depend on their hireachy\n",
    "prefix_col = 'Attribute_'\n",
    "df_volume = df_volume['Attribute'].str.split(\" ::: \", expand = True).add_prefix(prefix_col).join(df_volume)\n",
    "df_value = df_value['Attribute'].str.split(\" ::: \", expand = True).add_prefix(prefix_col).join(df_value)\n",
    "\n",
    "# drop Attribute column\n",
    "df_volume.drop(columns = [\"Attribute\"], inplace = True)\n",
    "df_value.drop(columns = [\"Attribute\"], inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Data Shaping 2 ###\n",
    "# remove head(total) row\n",
    "\n",
    "# get attribute list\n",
    "selected_col = [col for col in df_volume if col.startswith('Attribute_')]\n",
    "\n",
    "# identify head(total) row\n",
    "Row_to_Remove = []\n",
    "for i in range(len(selected_col)):\n",
    "    Attribute = 'Attribute_' + str(i)\n",
    "    for j in range(len(df_volume)):\n",
    "        \n",
    "        cur_val = df_volume[Attribute][j]\n",
    "        if j < len(df_volume)-1:\n",
    "            next_val = df_volume[Attribute][j+1]\n",
    "        else:\n",
    "            next_val = \"\"\n",
    "        if j > 0:\n",
    "            prev_val = df_volume[Attribute][j-1]\n",
    "        else:\n",
    "            prev_val = \"\"\n",
    "    \n",
    "        if cur_val != None and cur_val != prev_val and cur_val == next_val:\n",
    "            Row_to_Remove.append(j)\n",
    "\n",
    "# remove row head(total) row\n",
    "df_volume.drop(labels=Row_to_Remove,axis=0,inplace=True)\n",
    "df_value.drop(labels=Row_to_Remove,axis=0,inplace=True)\n",
    "\n",
    "# reset row index\n",
    "df_volume.reset_index(inplace=True,drop=True)\n",
    "df_value.reset_index(inplace=True,drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Data Shaping 3 ###\n",
    "\n",
    "# --- Volumn --- #\n",
    "# Unpivot MonthYear Column for Volumn \n",
    "level_col_list = [col_name for col_name in df_volume.columns if col_name.startswith(prefix_col)]\n",
    "value_col_list = [col_name for col_name in df_volume.columns if col_name not in level_col_list]\n",
    "df_volume = pd.melt(df_volume, id_vars = level_col_list, value_vars = value_col_list)\n",
    "\n",
    "# add column Measre\n",
    "df_volume['MeasureName'] = 'volume_k'\n",
    "\n",
    "\n",
    "# --- Value --- #\n",
    "# Unpivot MonthYear Column for Value \n",
    "level_col_list = [col_name for col_name in df_value.columns if col_name.startswith(prefix_col)]\n",
    "value_col_list = [col_name for col_name in df_value.columns if col_name not in level_col_list]\n",
    "df_value = pd.melt(df_value, id_vars = level_col_list, value_vars = value_col_list)\n",
    "\n",
    "# add column Measre\n",
    "df_value['MeasureName'] = 'value_b'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Data Shaping 4 ###\n",
    "# Union Volume(df_volume) and Value(df_value)\n",
    "df_final = pd.concat([df_volume,df_value])\n",
    "\n",
    "# rename column\n",
    "df_final.rename(columns = {\"Attribute_0\" : \"PaymentType\" , \"Attribute_1\" : \"SystemType\" , \"Attribute_2\" : \"ChannelType\"}, inplace = True)\n",
    "df_final.rename(columns = {\"variable\" : \"MonthYear\" , \"value\" : \"M_Value\"}, inplace = True)\n",
    "\n",
    "df_final['TransType'] = 'Transactions processed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save output to csv\n",
    "df_final.to_csv(f'../Clean/Txn_PaymentSystem_Clean.csv', index = False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3ca16441285d59f07b63f07e08decaf79ec679259e9400074ea76c72f33c3fe0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
