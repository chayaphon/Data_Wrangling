{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/chayaphon/Data_Wrangling/blob/main/Wrangling_Code/data_cleansing_Pastic_cards_usage.ipynb#scrollTo=IzFf1CXgipHb\" target=\"_blank\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : Index\n",
      "1 : Vol. of Plastic card usage\n",
      "2 : Value. of Plastic card usage\n",
      "3 : Mobile,internet banking\n",
      "4 : Promptpay\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Define sheet name\n",
    "FILE_NAME = '../Sources/Data.xlsx'\n",
    "\n",
    "# Get all sheet name in Excel file\n",
    "sheet_name_list = pd.ExcelFile(FILE_NAME).sheet_names\n",
    "\n",
    "# Show all sheet name and index number\n",
    "for index, sheet_name in enumerate(sheet_name_list):\n",
    "    print(f\"{index} : {sheet_name}\")\n",
    "\n",
    "# Read data base on selected SELECT_SHEET_NAME\n",
    "SELECT_SHEET_NAME_1 = sheet_name_list[1]\n",
    "SELECT_SHEET_NAME_2 = sheet_name_list[2]\n",
    "\n",
    "# add dataframe for Volume and Value sheet\n",
    "df_volume = pd.read_excel(FILE_NAME, sheet_name= SELECT_SHEET_NAME_1, skiprows = 5)\n",
    "df_value = pd.read_excel(FILE_NAME, sheet_name= SELECT_SHEET_NAME_2, skiprows = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Data Cleansing ###\n",
    "\n",
    "# --- Volume ---#\n",
    "# Change column name and drop un-related column\n",
    "df_volume.rename(columns = {\"Unnamed: 1\" : \"Attribute\"}, inplace = True)\n",
    "df_volume.dropna(subset = [\"Attribute\"], inplace = True)\n",
    "df_volume.drop(columns = [\"Unnamed: 0\"], inplace = True)\n",
    "df_volume.replace(\"n.a.\", np.nan, inplace = True)\n",
    "\n",
    "# Filter out last row of column 'Attribute'\n",
    "df_volume = df_volume[df_volume['Attribute'] != \"Total\"]\n",
    "\n",
    "# Cleansing Column name (trim and remove leeter after year)\n",
    "col_list_clean_volume = []\n",
    "col_list_trim_volume = [col_name.strip() for col_name in df_volume.columns]\n",
    "for col_name in col_list_trim_volume:\n",
    "    if len(col_name.split(\" \")) <= 2:\n",
    "        col_list_clean_volume.append(col_name)\n",
    "    else:\n",
    "        cleaned_col_name =  \" \".join(col_name.split(\" \")[:-1])\n",
    "        col_list_clean_volume.append(cleaned_col_name)\n",
    "        \n",
    "# Overwrite existing column with new columns clean column    \n",
    "df_volume.columns = col_list_clean_volume\n",
    "\n",
    "\n",
    "# --- Value ---#\n",
    "# Change column name and drop un-related column\n",
    "df_value.rename(columns = {\"Unnamed: 1\" : \"Attribute\"}, inplace = True)\n",
    "df_value.dropna(subset = [\"Attribute\"], inplace = True)\n",
    "df_value.drop(columns = [\"Unnamed: 0\"], inplace = True)\n",
    "df_value.replace(\"n.a.\", np.nan, inplace = True)\n",
    "\n",
    "# Filter out last row of column 'Attribute'\n",
    "df_value = df_value[df_value['Attribute'] != \"Total\"]\n",
    "\n",
    "# Cleansing Column name (trim and remove leeter after year)\n",
    "col_list_clean_volume = []\n",
    "col_list_trim_volume = [col_name.strip() for col_name in df_volume.columns]\n",
    "for col_name in col_list_trim_volume:\n",
    "    if len(col_name.split(\" \")) <= 2:\n",
    "        col_list_clean_volume.append(col_name)\n",
    "    else:\n",
    "        cleaned_col_name =  \" \".join(col_name.split(\" \")[:-1])\n",
    "        col_list_clean_volume.append(cleaned_col_name)\n",
    "        \n",
    "# Overwrite existing column with new columns clean column    \n",
    "df_value.columns = col_list_clean_volume\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Data Cleansing 2 ###\n",
    "# Remove /Number from 'Attribute' columns\n",
    "text_clean_list = []\n",
    "for text in list(df_volume['Attribute']):\n",
    "    if text.split(\" \")[-1].endswith(\"/\"):\n",
    "        text_clean_list.append(\" \".join(text.split(\" \")[:-1]))\n",
    "    else:\n",
    "        text_clean_list.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Data Shaping1 ###\n",
    "# Seperate each attribute as parent and sub-topic\n",
    "\n",
    "result_text_list = []\n",
    "Parent = []\n",
    "\n",
    "for index in range(len(text_clean_list)):\n",
    "    list_text = text_clean_list[index].split(\"   \")\n",
    "    \n",
    "    if len(list_text) == 1:\n",
    "        Parent = [list_text[0].strip()]\n",
    "        result_text_list.append(\" ::: \".join(Parent))\n",
    "    else:\n",
    "        Parent = Parent[:len(list_text)-1]\n",
    "        Parent.append(list_text[len(list_text)-1].strip())\n",
    "        result_text_list.append(\" ::: \".join(Parent))\n",
    "        \n",
    "# Assign new value to 'Attribute' column \n",
    "df_volume['Attribute'] = result_text_list\n",
    "df_value['Attribute'] = result_text_list\n",
    "\n",
    "# Expland Attribute into multiple columns depend on their hireachy\n",
    "prefix_col = 'Attribute_'\n",
    "df_volume = df_volume['Attribute'].str.split(\" ::: \", expand = True).add_prefix(prefix_col).join(df_volume)\n",
    "df_value = df_value['Attribute'].str.split(\" ::: \", expand = True).add_prefix(prefix_col).join(df_value)\n",
    "\n",
    "# drop Attribute column\n",
    "df_volume.drop(columns = [\"Attribute\"], inplace = True)\n",
    "df_value.drop(columns = [\"Attribute\"], inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Data Shaping 2 ###\n",
    "# remove head(total) row\n",
    "\n",
    "# get attribute list\n",
    "selected_col = [col for col in df_volume if col.startswith('Attribute_')]\n",
    "\n",
    "# identify head(total) row\n",
    "Row_to_Remove = []\n",
    "for i in range(len(selected_col)):\n",
    "    Attribute = 'Attribute_' + str(i)\n",
    "    for j in range(len(df_volume)):\n",
    "        \n",
    "        cur_val = df_volume[Attribute][j]\n",
    "        if j < len(df_volume)-1:\n",
    "            next_val = df_volume[Attribute][j+1]\n",
    "        else:\n",
    "            next_val = \"\"\n",
    "        if j > 0:\n",
    "            prev_val = df_volume[Attribute][j-1]\n",
    "        else:\n",
    "            prev_val = \"\"\n",
    "    \n",
    "        if cur_val != None and cur_val != prev_val and cur_val == next_val:\n",
    "            Row_to_Remove.append(j)\n",
    "\n",
    "# remove row head(total) row\n",
    "df_volume.drop(labels=Row_to_Remove,axis=0,inplace=True)\n",
    "df_value.drop(labels=Row_to_Remove,axis=0,inplace=True)\n",
    "\n",
    "# reset row index\n",
    "df_volume.reset_index(inplace=True,drop=True)\n",
    "df_value.reset_index(inplace=True,drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Data Shaping 3 ###\n",
    "\n",
    "# --- Volumn --- #\n",
    "# Unpivot MonthYear Column for Volumn \n",
    "level_col_list = [col_name for col_name in df_volume.columns if col_name.startswith(prefix_col)]\n",
    "value_col_list = [col_name for col_name in df_volume.columns if col_name not in level_col_list]\n",
    "df_volume = pd.melt(df_volume, id_vars = level_col_list, value_vars = value_col_list)\n",
    "\n",
    "# add column Measre\n",
    "df_volume['MeasureName'] = 'volume_k'\n",
    "\n",
    "\n",
    "# --- Value --- #\n",
    "# Unpivot MonthYear Column for Volumn \n",
    "level_col_list = [col_name for col_name in df_value.columns if col_name.startswith(prefix_col)]\n",
    "value_col_list = [col_name for col_name in df_value.columns if col_name not in level_col_list]\n",
    "df_value = pd.melt(df_value, id_vars = level_col_list, value_vars = value_col_list)\n",
    "\n",
    "# add column Measre\n",
    "df_value['MeasureName'] = 'value_b'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Data Shaping 4 ###\n",
    "# Union Volume(df_volume) and Value(df_value)\n",
    "df_final = pd.concat([df_volume,df_value])\n",
    "\n",
    "# rename column\n",
    "df_final.rename(columns = {\"Attribute_0\" : \"ChannelType\" , \"Attribute_1\" : \"UsageType\"}, inplace = True)\n",
    "df_final.rename(columns = {\"variable\" : \"MonthYear\" , \"value\" : \"M_Value\"}, inplace = True)\n",
    "\n",
    "df_final['TransType'] = 'Plastic cards'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save output to csv\n",
    "df_final.to_csv(f'../Clean/Pastic_cards_usage_Clean.csv', index = False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataAnalytics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "797f7ad4b106c7f7f8bfc247a509a8f940d3b783f7f877a639874fd9a8adccb7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
