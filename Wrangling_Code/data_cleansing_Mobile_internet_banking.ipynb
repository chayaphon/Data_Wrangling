{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : Index\n",
      "1 : Vol. of Plastic card usage\n",
      "2 : Value. of Plastic card usage\n",
      "3 : Payment Cards on ATM & POS \n",
      "4 : Mobile,internet banking\n",
      "5 : e-Money\n",
      "6 : promptpay\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Define sheet name\n",
    "FILE_NAME = '../Sources/Data.xlsx'\n",
    "\n",
    "# Get all sheet name in Excel file\n",
    "sheet_name_list = pd.ExcelFile(FILE_NAME).sheet_names\n",
    "\n",
    "# Show all sheet name and index number\n",
    "for index, sheet_name in enumerate(sheet_name_list):\n",
    "    print(f\"{index} : {sheet_name}\")\n",
    "\n",
    "# Read data base on selected SELECT_SHEET_NAME\n",
    "SELECT_SHEET_NAME_1 = sheet_name_list[4]\n",
    "\n",
    "# add dataframe for selected sheet\n",
    "df = pd.read_excel(FILE_NAME, sheet_name= SELECT_SHEET_NAME_1, skiprows = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Data Cleansing ###\n",
    "\n",
    "# Change column name and drop un-related column\n",
    "df.rename(columns = {\"Unnamed: 1\" : \"Attribute\"}, inplace = True)\n",
    "df.dropna(subset = [\"Attribute\"], inplace = True)\n",
    "df.drop(columns = [\"Unnamed: 0\"], inplace = True)\n",
    "df.replace(\"n.a.\", np.nan, inplace = True)\n",
    "\n",
    "# Cleansing Column name (trim and remove leeter after year)\n",
    "col_list_clean = []\n",
    "col_list_trim = [col_name.strip() for col_name in df.columns]\n",
    "for col_name in col_list_trim:\n",
    "    if len(col_name.split(\" \")) <= 2:\n",
    "        col_list_clean.append(col_name)\n",
    "    else:\n",
    "        cleaned_col_name =  \" \".join(col_name.split(\" \")[:-1])\n",
    "        col_list_clean.append(cleaned_col_name)\n",
    "        \n",
    "# Overwrite existing column with new columns clean column    \n",
    "df.columns = col_list_clean\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Data Cleansing 2 ###\n",
    "\n",
    "# Remove /Number from 'Attribute' columns\n",
    "text_clean_list = []\n",
    "for text in list(df['Attribute']):\n",
    "    if text.split(\" \")[-1].endswith(\"/\"):\n",
    "        text_clean_list.append(\" \".join(text.split(\" \")[:-1]))\n",
    "    else:\n",
    "        text_clean_list.append(text)\n",
    "        \n",
    "# replace value\n",
    "for i in range(len(text_clean_list)):\n",
    "    if text_clean_list[i].startswith(\"   No.\"):\n",
    "        text_clean_list[i] = '   agreements'\n",
    "    if text_clean_list[i].startswith(\"   Volume\"):\n",
    "        text_clean_list[i] = '   volume_k'\n",
    "    if text_clean_list[i].startswith(\"   Value\"):\n",
    "        text_clean_list[i] = '   value_b'\n",
    "\n",
    "df['Attribute'] = text_clean_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Data Shaping1 ###\n",
    "# Seperate each attribute as parent and sub-topic\n",
    "\n",
    "result_text_list = []\n",
    "Parent = []\n",
    "\n",
    "for index in range(len(text_clean_list)):\n",
    "    list_text = text_clean_list[index].split(\"   \")\n",
    "    \n",
    "    if len(list_text) == 1:\n",
    "        Parent = [list_text[0].strip()]\n",
    "        result_text_list.append(\" ::: \".join(Parent))\n",
    "    else:\n",
    "        Parent = Parent[:len(list_text)-1]\n",
    "        Parent.append(list_text[len(list_text)-1].strip())\n",
    "        result_text_list.append(\" ::: \".join(Parent))\n",
    "        \n",
    "# Assign new value to 'Attribute' column \n",
    "df['Attribute'] = result_text_list\n",
    "\n",
    "# Expland Attribute into multiple columns depend on their hireachy\n",
    "prefix_col = 'Attribute_'\n",
    "df = df['Attribute'].str.split(\" ::: \", expand = True).add_prefix(prefix_col).join(df)\n",
    "\n",
    "# drop Attribute column\n",
    "df.drop(columns = [\"Attribute\"], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Data Shaping 2 ###\n",
    "# remove head(total) row\n",
    "\n",
    "# get attribute list\n",
    "selected_col = [col for col in df if col.startswith('Attribute_')]\n",
    "\n",
    "# identify head(total) row\n",
    "Row_to_Remove = []\n",
    "for i in range(len(selected_col)):\n",
    "    Attribute = 'Attribute_' + str(i)\n",
    "    for j in range(len(df)):\n",
    "        \n",
    "        cur_val = df[Attribute][j]\n",
    "        if j < len(df)-1:\n",
    "            next_val = df[Attribute][j+1]\n",
    "        else:\n",
    "            next_val = \"\"\n",
    "        if j > 0:\n",
    "            prev_val = df[Attribute][j-1]\n",
    "        else:\n",
    "            prev_val = \"\"\n",
    "    \n",
    "        if cur_val != None and cur_val != prev_val and cur_val == next_val:\n",
    "            Row_to_Remove.append(j)\n",
    "\n",
    "# remove row head(total) row\n",
    "df.drop(labels=Row_to_Remove,axis=0,inplace=True)\n",
    "\n",
    "# reset row index\n",
    "df.reset_index(inplace=True,drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Data Shaping 3 ###\n",
    "\n",
    "# list Attribute and Measure column\n",
    "attribute_col_list = [col_name for col_name in df.columns if col_name.startswith(prefix_col)]\n",
    "measure_col_list = [col_name for col_name in df.columns if col_name not in attribute_col_list]\n",
    "\n",
    "# Remove blank value row (header column)\n",
    "df.dropna(axis=0, subset=measure_col_list, how='all', inplace = True)\n",
    "\n",
    "# Unoivot MonthYear Column\n",
    "df = pd.melt(df, id_vars = attribute_col_list, value_vars = measure_col_list)\n",
    "\n",
    "# rename column\n",
    "df.rename(columns = {\"Attribute_0\" : \"ChannelType\" , \"Attribute_1\" : \"MeasureName\", \"Attribute_2\" : \"UsageType\"}, inplace = True)\n",
    "df.rename(columns = {\"variable\" : \"MonthYear\" , \"value\" : \"M_Value\"}, inplace = True)\n",
    "\n",
    "# add column Measre\n",
    "df['TransType'] = 'Online Banking'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save output to csv\n",
    "df.to_csv(f'../Clean/Mobile_internet_banking_Clean.csv', index = False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataAnalytics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "797f7ad4b106c7f7f8bfc247a509a8f940d3b783f7f877a639874fd9a8adccb7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
